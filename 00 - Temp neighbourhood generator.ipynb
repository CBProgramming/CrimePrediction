{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_neighborhoods():\n",
    "    df = pd.read_csv('SF_neighborhoods.csv')\n",
    "    print(\"Neighborhoods dataset opened.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhoods(df):\n",
    "    neighborhoods = []\n",
    "    num_neighborhoods = len(df.index)\n",
    "    for x in range(0,num_neighborhoods):\n",
    "        neighborhoods.append(df.iloc[x,2])\n",
    "    return neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neighborhood_polygons(df):\n",
    "    neighborhoods = []\n",
    "    num_neighborhoods = len(df.index)\n",
    "    for x in range(0,num_neighborhoods):\n",
    "        raw_polygon_data = df.iloc[x,1]\n",
    "        neighborhood_polygon = generate_polygon(raw_polygon_data)\n",
    "        neighborhood_name = df.iloc[x,2]\n",
    "        neighborhood_tuple = (neighborhood_polygon,neighborhood_name)\n",
    "        neighborhoods.append(neighborhood_tuple)\n",
    "    return neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polygon(raw_polygon_data):\n",
    "    raw_polygon_data = raw_polygon_data[16:-3]\n",
    "    coords = ''\n",
    "    coords_list = []\n",
    "    for char in raw_polygon_data:\n",
    "        if char == ' ' or char == ',':\n",
    "            if coords != '':\n",
    "                coords_list.append(float(coords))\n",
    "            coords = ''\n",
    "        else:\n",
    "            coords = coords+char\n",
    "    coords_list.append(float(coords))\n",
    "    x = 0\n",
    "    tuple_list = []\n",
    "    while x < len(coords_list):\n",
    "        next_tuple = (coords_list[x+1],coords_list[x])\n",
    "        tuple_list.append(next_tuple)\n",
    "        x+=2\n",
    "    polygon = Polygon(tuple_list)\n",
    "    return polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_sfpd_data():\n",
    "    df = pd.read_csv('SFPD_original.csv')\n",
    "    print(\"SFPD criminal incident dataset opened.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_uncategorised_incidents(df):\n",
    "    #identify total number of records and remove uncategorised crimes\n",
    "    total_records = len(df.index)\n",
    "    categorised_crimes = df['Incident Category'].count()\n",
    "    uncategorised_crimes = total_records - categorised_crimes\n",
    "    print(\"Total records:\",total_records)\n",
    "    print(\"Incidents Categorised:\",categorised_crimes)\n",
    "    print(\"Incidents Uncategorised:\",uncategorised_crimes)\n",
    "    if uncategorised_crimes != 0:\n",
    "        #drop blank incident categories and recheck values\n",
    "        df = df.dropna(subset=['Incident Category'])\n",
    "        df = remove_uncategorised_incidents(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_with_missing_values(df):\n",
    "    print(\"Removing rows with missing values...\")\n",
    "    num_rows = len(df.index)\n",
    "    df = df.dropna()\n",
    "    new_num_rows = len(df.index)\n",
    "    rows_removed = num_rows - new_num_rows\n",
    "    print(rows_removed,\"rows removed\")\n",
    "    print(new_num_rows,\"rows remaining\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_indexes(df):\n",
    "    return df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unnecessary_columns(df):\n",
    "    df = df.drop(columns=['Report Datetime','Row ID', 'Incident ID',\n",
    "                          'Incident Number','CAD Number','Report Type Code',\n",
    "                          'Report Type Description', 'Filed Online',\n",
    "                          'Incident Code','Incident Subcategory',\n",
    "                          'Incident Description', 'Resolution', 'Intersection',\n",
    "                          'CNN','Police District','Analysis Neighborhood',\n",
    "                          'Supervisor District', 'point', 'SF Find Neighborhoods',\n",
    "                          'Current Police Districts', 'Current Supervisor Districts',\n",
    "                          'Analysis Neighborhoods','HSOC Zones as of 2018-06-05',\n",
    "                          'OWED Public Spaces',\n",
    "                          'Central Market/Tenderloin Boundary Polygon - Updated',\n",
    "                          'Parks Alliance CPSI (27+TL sites)','ESNCAG - Boundary File',\n",
    "                          'Areas of Vulnerability, 2016'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_of_non_crime(df):\n",
    "    print(\"Removing crimes categorised as:\")\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Case Closure')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Courtesy Report')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Lost Property')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Missing Person')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Non-Criminal')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Suicide')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Vehicle Misplaced')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Warrant')]\n",
    "    print(len(df.index),\"rows remaining\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_crime_prior_to_uber_legislation_change(df):\n",
    "    df['Incident Date'] = pd.to_datetime(df['Incident Date'])\n",
    "    df = df[~(df['Incident Date'] < '2018-07-01')]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gps_to_neighborhood(df,neighborhood_polygons):\n",
    "    df['Neighborhood'] = np.nan\n",
    "    num_records = len(df.index)\n",
    "    for incident_num in range(0,num_records):\n",
    "        df.iloc[incident_num,8] = ''\n",
    "        shortest_distance = 999999999\n",
    "        closest_neighborhood = ''\n",
    "        latitude = float(df.iloc[incident_num,6])\n",
    "        longitude = float(df.iloc[incident_num,7])\n",
    "        point = Point(latitude,longitude)\n",
    "        for poly_tuple in neighborhood_polygons:\n",
    "            if poly_tuple[0].contains(point) or poly_tuple[0].touches(point):\n",
    "                df.iloc[incident_num,8] = poly_tuple[1]\n",
    "                break\n",
    "            else:\n",
    "                distance_to_neighborhood = point.distance(poly_tuple[0])\n",
    "                if distance_to_neighborhood < shortest_distance:\n",
    "                    shortest_distance = distance_to_neighborhood\n",
    "                    closest_neighborhood = poly_tuple[1]\n",
    "        if df.iloc[incident_num,8] == '':\n",
    "            #place incident in closest neighborhood\n",
    "            df.iloc[incident_num,8] = closest_neighborhood\n",
    "            #shortest distance is over 1 mile away\n",
    "            if shortest_distance > 0.018:\n",
    "                print('WARNING!!! GPS coordinates for row',incident_num,'do not appear to be within 1 mile of a San Francisco Neighbourhood')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighborhoods dataset opened.\n"
     ]
    }
   ],
   "source": [
    "df = open_neighborhoods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = get_neighborhoods(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_polygons = generate_neighborhood_polygons(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFPD criminal incident dataset opened.\n"
     ]
    }
   ],
   "source": [
    "df = open_sfpd_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 402706\n",
      "Incidents Categorised: 402426\n",
      "Incidents Uncategorised: 280\n",
      "Total records: 402426\n",
      "Incidents Categorised: 402426\n",
      "Incidents Uncategorised: 0\n"
     ]
    }
   ],
   "source": [
    "df = remove_uncategorised_incidents(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_unnecessary_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing rows with missing values...\n",
      "20753 rows removed\n",
      "381673 rows remaining\n"
     ]
    }
   ],
   "source": [
    "df = remove_rows_with_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing crimes categorised as:\n",
      "320556 rows remaining\n"
     ]
    }
   ],
   "source": [
    "df = remove_rows_of_non_crime(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_crime_prior_to_uber_legislation_change(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_gps_to_neighborhood(df,neighborhood_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_indexes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('temp_neighbourhood_thingy.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
