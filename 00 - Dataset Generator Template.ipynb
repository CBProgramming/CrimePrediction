{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1864,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon\n",
    "import copy\n",
    "import time\n",
    "import re\n",
    "from datetime import date, datetime, timedelta\n",
    "from shapely.geometry import Point, Polygon\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Do not amend this template.<h1>\n",
    "<h1>Make a copy and adjust values in the below cell accordingly.<h1>\n",
    "<h1>No other cell requires adjustment.<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1865,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_data_name = \"SF_neighborhoods.csv\"\n",
    "sfpd_data_name = \"incidents_new_data.csv\" #current range 12/11/2020 to 28/01/2021\n",
    "business_data_name = \"business_new_data.csv\"\n",
    "final_data_name = \"new_final_data.csv\"\n",
    "start_day = 12\n",
    "start_month = 11\n",
    "start_year = 2020\n",
    "end_day = 28\n",
    "end_month = 1\n",
    "end_year = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1866,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_string = str(start_year)+'-'+str(start_month)+'-'+str(start_day)\n",
    "start_date = date(start_year,start_month,start_day)\n",
    "one_year_before_start_date = start_date - timedelta(days=365)\n",
    "end_date = date (end_year,end_month,end_day)\n",
    "date_after_end_date = end_date + timedelta(days=1)\n",
    "future_year_increment = 50\n",
    "future_date = str(end_year+future_year_increment)+'-'+str(end_month)+'-'+str(end_day)\n",
    "future_year = end_year + future_year_increment\n",
    "business_start_date = str(start_month)+'-'+str(start_day)+'-'+str(start_year)\n",
    "business_end_date = str(end_month)+'-'+str(end_day)+'-'+str(end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get neighbourhood data <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1867,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_neighborhoods():\n",
    "    df = pd.read_csv(neighbourhood_data_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1868,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhoods(df):\n",
    "    neighborhoods = []\n",
    "    num_neighborhoods = len(df.index)\n",
    "    for x in range(0,num_neighborhoods):\n",
    "        neighborhoods.append(df.iloc[x,2])\n",
    "    return neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1869,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neighborhood_polygons(df):\n",
    "    neighborhoods = []\n",
    "    num_neighborhoods = len(df.index)\n",
    "    for x in range(0,num_neighborhoods):\n",
    "        raw_polygon_data = df.iloc[x,1]\n",
    "        neighborhood_polygon = generate_polygon(raw_polygon_data)\n",
    "        neighborhood_name = df.iloc[x,2]\n",
    "        neighborhood_tuple = (neighborhood_polygon,neighborhood_name)\n",
    "        neighborhoods.append(neighborhood_tuple)\n",
    "    return neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1870,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polygon(raw_polygon_data):\n",
    "    raw_polygon_data = raw_polygon_data[16:-3]\n",
    "    coords = ''\n",
    "    coords_list = []\n",
    "    for char in raw_polygon_data:\n",
    "        if char == ' ' or char == ',':\n",
    "            if coords != '':\n",
    "                coords_list.append(float(coords))\n",
    "            coords = ''\n",
    "        else:\n",
    "            coords = coords+char\n",
    "    coords_list.append(float(coords))\n",
    "    x = 0\n",
    "    tuple_list = []\n",
    "    while x < len(coords_list):\n",
    "        next_tuple = (coords_list[x+1],coords_list[x])\n",
    "        tuple_list.append(next_tuple)\n",
    "        x+=2\n",
    "    polygon = Polygon(tuple_list)\n",
    "    return polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1871,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_neighborhoods()\n",
    "neighborhoods = get_neighborhoods(df)\n",
    "num_neighbourhoods = len(neighborhoods)\n",
    "neighborhood_polygons = generate_neighborhood_polygons(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get incident report data <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1872,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_sfpd_data():\n",
    "    df = pd.read_csv(sfpd_data_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1873,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_uncategorised_incidents(df):\n",
    "    #identify total number of records and remove uncategorised crimes\n",
    "    total_records = len(df.index)\n",
    "    categorised_crimes = df['Incident Category'].count()\n",
    "    uncategorised_crimes = total_records - categorised_crimes\n",
    "    if uncategorised_crimes != 0:\n",
    "        #drop blank incident categories and recheck values\n",
    "        df = df.dropna(subset=['Incident Category'])\n",
    "        df = remove_uncategorised_incidents(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1874,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_with_missing_values(df):\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1875,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unnecessary_incident_columns(df):\n",
    "    df = df.drop(columns=['Report Datetime','Row ID', 'Incident ID',\n",
    "                          'Incident Number','CAD Number','Report Type Code',\n",
    "                          'Report Type Description', 'Filed Online',\n",
    "                          'Incident Code','Incident Subcategory',\n",
    "                          'Incident Description', 'Resolution', 'Intersection',\n",
    "                          'CNN','Police District','Analysis Neighborhood',\n",
    "                          'Supervisor District', 'point', 'SF Find Neighborhoods',\n",
    "                          'Current Police Districts', 'Current Supervisor Districts',\n",
    "                          'Analysis Neighborhoods','HSOC Zones as of 2018-06-05',\n",
    "                          'OWED Public Spaces',\n",
    "                          'Central Market/Tenderloin Boundary Polygon - Updated',\n",
    "                          'Parks Alliance CPSI (27+TL sites)','ESNCAG - Boundary File',\n",
    "                          'Areas of Vulnerability, 2016'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1876,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_of_non_crime(df):\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Case Closure')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Courtesy Report')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Lost Property')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Missing Person')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Non-Criminal')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Suicide')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Vehicle Misplaced')]\n",
    "    df = df.loc[~df['Incident Category'].str.contains('Warrant')]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1877,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_crime_prior_to_start_date(df):\n",
    "    df['Incident Date'] = pd.to_datetime(df['Incident Date'],dayfirst=True)\n",
    "    df = df[~(df['Incident Date'].dt.date < one_year_before_start_date)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1878,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gps_to_neighborhood(df,neighborhood_polygons):\n",
    "    df['Neighborhood'] = np.nan\n",
    "    num_records = len(df.index)\n",
    "    for incident_num in range(0,num_records):\n",
    "        df.iloc[incident_num,8] = ''\n",
    "        shortest_distance = 999999999\n",
    "        closest_neighborhood = ''\n",
    "        latitude = float(df.iloc[incident_num,6])\n",
    "        longitude = float(df.iloc[incident_num,7])\n",
    "        point = Point(latitude,longitude)\n",
    "        for poly_tuple in neighborhood_polygons:\n",
    "            if poly_tuple[0].contains(point) or poly_tuple[0].touches(point):\n",
    "                df.iloc[incident_num,8] = poly_tuple[1]\n",
    "                break\n",
    "            else:\n",
    "                distance_to_neighborhood = point.distance(poly_tuple[0])\n",
    "                if distance_to_neighborhood < shortest_distance:\n",
    "                    shortest_distance = distance_to_neighborhood\n",
    "                    closest_neighborhood = poly_tuple[1]\n",
    "        if df.iloc[incident_num,8] == '':\n",
    "            #place incident in closest neighborhood\n",
    "            df.iloc[incident_num,8] = closest_neighborhood\n",
    "            #shortest distance is over 1 mile away\n",
    "            if shortest_distance > 0.018:\n",
    "                print('WARNING!!! GPS coordinates for row',incident_num,'do not appear to be within 1 mile of a San Francisco Neighbourhood')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1879,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gps_coordinates(df):\n",
    "    df = df.drop(columns=['Latitude','Longitude'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1880,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reports_per_day_per_neighborhood(df):\n",
    "    df.to_csv(\"sfpd_pre_per_day.csv\", index = False)\n",
    "    df['Todays Reports'] = 1\n",
    "    df['Incident Date'] = pd.to_datetime(df['Incident Date'],dayfirst=True)\n",
    "    df = df.groupby(['Incident Date',\n",
    "                     'Incident Year', \n",
    "                     'Neighborhood',\n",
    "                     'Incident Day of Week'\n",
    "                    ]).count()\n",
    "    df = df.drop(columns=[ 'Incident Datetime','Incident Time',\n",
    "                           'Incident Category'])\n",
    "    df = df.reset_index()\n",
    "    df.to_csv(\"sfpd_post_per_day.csv\", index = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1881,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_missing_neighborhoods(df,neighborhoods):\n",
    "    new_rows = pd.DataFrame()\n",
    "    num_records = len(df.index)\n",
    "    current_date = df.iloc[0,0]\n",
    "    zero_crime_neighborhoods = copy.deepcopy(neighborhoods)\n",
    "    for record in range(0,num_records):\n",
    "        zero_crime_neighborhoods.remove(df.iloc[record,2])\n",
    "        if record != num_records-1:\n",
    "            if df.iloc[record+1,0] != current_date:\n",
    "                for neighborhood in zero_crime_neighborhoods:\n",
    "                    new_row = {'Incident Date' : current_date,\n",
    "                               'Incident Year' : df.iloc[record-1,1],\n",
    "                               'Neighborhood' : neighborhood,\n",
    "                               'Incident Day of Week' : df.iloc[record-1,3],\n",
    "                               'Todays Reports' : 0}\n",
    "                    new_rows = new_rows.append(new_row,ignore_index=True)\n",
    "                zero_crime_neighborhoods = copy.deepcopy(neighborhoods)\n",
    "                current_date = df.iloc[record+1,0]\n",
    "    for neighborhood in zero_crime_neighborhoods:\n",
    "        new_row = {'Incident Date' : current_date,\n",
    "                    'Incident Year' : df.iloc[len(df.index)-1,1],\n",
    "                    'Neighborhood' : neighborhood,\n",
    "                    'Incident Day of Week' : df.iloc[len(df.index)-1,3],\n",
    "                    'Todays Reports' : 0}\n",
    "        new_rows = new_rows.append(new_row,ignore_index=True)\n",
    "    frames = [df,new_rows]\n",
    "    new_record = pd.concat(frames)\n",
    "    new_record = new_record.sort_values(['Incident Date','Neighborhood'])\n",
    "    return new_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1882,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_14_days(df):\n",
    "    transitional_data = df.shift(periods=(num_neighbourhoods*7))\n",
    "    transitional_data = transitional_data['Last 7 days reports']\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1883,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_28_days(df):\n",
    "    transitional_data = df.shift(periods=(num_neighbourhoods*14))\n",
    "    transitional_data = transitional_data['Last 14 days reports']\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1884,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_date_data(df):\n",
    "    df['Reports 1 day ago'] = shift_crimes(df,1)\n",
    "    df['Reports 2 days ago'] = shift_crimes(df,2)\n",
    "    df['Reports 3 days ago'] = shift_crimes(df,3)\n",
    "    df['Reports 4 days ago'] = shift_crimes(df,4)\n",
    "    df['Reports 5 days ago'] = shift_crimes(df,5)\n",
    "    df['Reports 6 days ago'] = shift_crimes(df,6)\n",
    "    df['Reports 7 days ago'] = shift_crimes(df,7)\n",
    "    df['Reports 14 days ago'] = shift_crimes(df,14)\n",
    "    df['Reports 30 days ago'] = shift_crimes(df,30)\n",
    "    df['Reports 365 days ago'] = shift_crimes(df,365)\n",
    "    df['Last 7 days reports'] = (df['Reports 1 day ago'] + df['Reports 2 days ago'] + df['Reports 3 days ago']\n",
    "                         + df['Reports 4 days ago'] + df['Reports 5 days ago']\n",
    "                         + df['Reports 6 days ago'] + df['Reports 7 days ago'])\n",
    "    df['Last 14 days reports'] = (df['Last 7 days reports'] + get_last_14_days(df))\n",
    "    df['Last 28 days reports'] = (df['Last 14 days reports'] + get_last_28_days(df))\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1885,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_indexes(df):\n",
    "    #print(\"Resetting indexes\")\n",
    "    #print(df)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    #print(\"Returning reset df\")\n",
    "    #print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1886,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_crimes(df,num_days):\n",
    "    #print(\"Incoming df to shift by days: \" + str(num_days))\n",
    "    #print(df)\n",
    "    transitional_data = df.shift(periods=(num_neighbourhoods*num_days))\n",
    "    #print(\"Transitional Data:\")\n",
    "    #print(transitional_data)\n",
    "    transitional_data = transitional_data['Todays Reports']\n",
    "    #print(\"Transitional Data:\")\n",
    "    #print(transitional_data)\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1887,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Incident data generation\n",
    "sfpd_df = open_sfpd_data()\n",
    "sfpd_df = remove_uncategorised_incidents(sfpd_df)\n",
    "sfpd_df = drop_unnecessary_incident_columns(sfpd_df)\n",
    "sfpd_df = remove_rows_with_missing_values(sfpd_df)\n",
    "sfpd_df = remove_rows_of_non_crime(sfpd_df)\n",
    "#sfpd_df.to_csv(\"mid_process5.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1888,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfpd_df = pd.read_csv(\"mid_process5.csv\")\n",
    "sfpd_df = remove_crime_prior_to_start_date(sfpd_df)\n",
    "#sfpd_df.to_csv(\"mid_process6.csv\", index = False)\n",
    "sfpd_df = convert_gps_to_neighborhood(sfpd_df,neighborhood_polygons)\n",
    "#sfpd_df.to_csv(\"mid_process7.csv\", index = False)\n",
    "sfpd_df = remove_gps_coordinates(sfpd_df)\n",
    "#sfpd_df.to_csv(\"mid_process8.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1889,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfpd_df = pd.read_csv(\"mid_process.csv\")\n",
    "sfpd_df = get_reports_per_day_per_neighborhood(sfpd_df)\n",
    "sfpd_df = check_for_missing_neighborhoods(sfpd_df,neighborhoods)\n",
    "sfpd_df = reset_indexes(sfpd_df)\n",
    "sfpd_df = generate_new_date_data(sfpd_df)\n",
    "sfpd_df = reset_indexes(sfpd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get business data<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1917,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_businesses():\n",
    "    df = pd.read_csv(business_data_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1918,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unnecessary_columns(df):\n",
    "    df = df.drop(columns=['Analysis Neighborhoods','Current Supervisor Districts',\n",
    "                          'Current Police Districts','SF Find Neighborhoods','Neighborhoods',\n",
    "                          'LIC Code Description','LIC Code','Transient Occupancy Tax','Parking Tax',\n",
    "                          'NAICS Code','Mail State','Mail City','Location Id','Business Account Number',\n",
    "                          'Business Start Date','Business End Date','Ownership Name','Street Address',\n",
    "                          'City','State','Source Zipcode','Mail Address','Mail Zipcode',\n",
    "                          'Supervisor District','Business Corridor','NAICS Code Description','UniqueID'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1919,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusted crime dataset starts 01/07/2019, business closed one year prior to this are not required \n",
    "def drop_end_dates_before_uber_legislation_change(df):\n",
    "    # give none closed businesses an arbitray future closure date\n",
    "    df['Location End Date'] = df['Location End Date'].fillna(future_date)\n",
    "    #convert all date strings to datetime\n",
    "    df['Location End Date'] = pd.to_datetime(df['Location End Date'])\n",
    "    df = df[~(df['Location End Date'].dt.date < one_year_before_start_date)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_neighborhood_by_geolocation(df, neighborhood_polygons,neighborhoods):\n",
    "    #replace blank gps coords with arbitrary point a significant distance from san francisco, in the ocean\n",
    "    df['Business Location'] = df['Business Location'].fillna('POINT (-120.0 30.00)')\n",
    "    df['Business Location'] = df['Business Location'].str[7:-1]\n",
    "    df[['Longitude','Latitude']] = df['Business Location'].str.split(\" \", expand = True)\n",
    "    df = convert_gps_to_neighborhood(df,neighborhood_polygons,neighborhoods)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1921,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gps_to_neighborhood(df,neighborhood_polygons,neighborhoods):\n",
    "    #print(df)\n",
    "    #df.to_csv(\"saved_data_to_check\", index = False)\n",
    "    df['Neighborhood'] = np.nan\n",
    "    num_records = len(df.index)\n",
    "    for business_num in range(0,num_records):\n",
    "        df.iloc[business_num,7] = ''\n",
    "        if df.iloc[business_num,4] == '-120.0 30.00':\n",
    "            for neighborhood in neighborhoods:\n",
    "                if df.iloc[business_num,3] == neighborhood:\n",
    "                    df.iloc[business_num,7] = neighborhood\n",
    "            if df.iloc[business_num,7] == '':\n",
    "                df.iloc[business_num,7] = 'no gps'     \n",
    "        else:\n",
    "            shortest_distance = 999999999\n",
    "            closest_neighborhood = ''\n",
    "            latitude = float(df.iloc[business_num,6])\n",
    "            longitude = float(df.iloc[business_num,5])\n",
    "            point = Point(latitude,longitude)\n",
    "            for poly_tuple in neighborhood_polygons:\n",
    "                if poly_tuple[0].contains(point) or poly_tuple[0].touches(point):\n",
    "                    df.iloc[business_num,7] = poly_tuple[1]\n",
    "                    break\n",
    "                else:\n",
    "                    distance_to_neighborhood = point.distance(poly_tuple[0])\n",
    "                    if distance_to_neighborhood < shortest_distance:\n",
    "                        shortest_distance = distance_to_neighborhood\n",
    "                        closest_neighborhood = poly_tuple[1]\n",
    "            if df.iloc[business_num,7] == '':\n",
    "                #if less than half a mile from a neighborhood polygon and sufficiently north to be san francisco\n",
    "                if shortest_distance < 0.018 and latitude > 37.709126:\n",
    "                    df.iloc[business_num,7] = closest_neighborhood\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df[df.Neighborhood != '']\n",
    "    df = df[df.Neighborhood != 'no gps']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1922,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_columns(df):\n",
    "    #print(\"cleanup\")\n",
    "    #print(df.head())\n",
    "    df = df.drop(columns=['Neighborhoods - Analysis Boundaries','Business Location',\n",
    "                          'Longitude','Latitude'])\n",
    "    #print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1923,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closures_per_day_per_neighborhood(closures):\n",
    "    #print(\"closures per day\")\n",
    "    #print(closures.head())\n",
    "    closures['Closures'] = 1\n",
    "    closures['Location End Date'] = pd.to_datetime(closures['Location End Date'])\n",
    "    closures = closures[closures['Location End Date'].dt.year < future_year]\n",
    "    closures = closures.groupby(['Location End Date','Neighborhood']).count()\n",
    "    closures = closures.drop(columns=[ 'DBA Name','Location Start Date'])\n",
    "    closures = closures.reset_index()\n",
    "    #print(closures.head())\n",
    "    return closures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1924,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zero_closure_neighborhoods(closures, neighborhoods):\n",
    "    new_rows = pd.DataFrame()\n",
    "    num_records = len(closures.index)\n",
    "    current_date = closures.iloc[0,0]\n",
    "    zero_closure_neighborhoods = copy.deepcopy(neighborhoods)\n",
    "    for record in range(0,num_records):\n",
    "        while closures.iloc[record,0] != current_date:\n",
    "            for neighborhood in zero_closure_neighborhoods:\n",
    "                new_row = {'Location End Date' : current_date,\n",
    "                                   'Neighborhood' : neighborhood,\n",
    "                                   'Closures' : 0}\n",
    "                new_rows = new_rows.append(new_row,ignore_index=True)\n",
    "            current_date = current_date + timedelta(days=1)\n",
    "        if closures.iloc[record,0] == current_date:\n",
    "            zero_closure_neighborhoods.remove(closures.iloc[record,1])\n",
    "            if record != num_records-1:\n",
    "                if closures.iloc[record+1,0] != current_date:\n",
    "                    for neighborhood in zero_closure_neighborhoods:\n",
    "                        new_row = {'Location End Date' : current_date,\n",
    "                                   'Neighborhood' : neighborhood,\n",
    "                                   'Closures' : 0}\n",
    "                        new_rows = new_rows.append(new_row,ignore_index=True)\n",
    "                    zero_closure_neighborhoods = copy.deepcopy(neighborhoods)\n",
    "                    current_date = current_date + timedelta(days=1)\n",
    "        if current_date == date_after_end_date:\n",
    "            break\n",
    "    for neighborhood in zero_closure_neighborhoods:\n",
    "        new_row = {'Location End Date' : current_date,\n",
    "                    'Neighborhood' : neighborhood,\n",
    "                    'Closures' : 0}\n",
    "        new_rows = new_rows.append(new_row,ignore_index=True)\n",
    "    frames = [closures,new_rows]\n",
    "    new_record = pd.concat(frames)\n",
    "    new_record = new_record.sort_values(['Location End Date','Neighborhood'])\n",
    "    return new_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1925,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_closures(closures,num_days):\n",
    "    transitional_data = closures.shift(periods=(num_neighbourhoods*num_days))\n",
    "    transitional_data = transitional_data['Closures']\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1926,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_14_days_closures(closures):\n",
    "    transitional_data = closures.shift(periods=(num_neighbourhoods*7))\n",
    "    transitional_data = transitional_data['Last 7 days closures']\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1927,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_28_days_closures(closures):\n",
    "    transitional_data = closures.shift(periods=(num_neighbourhoods*14))\n",
    "    transitional_data = transitional_data['Last 14 days closures']\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1928,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_closure_date_data(closures):\n",
    "    closures['Closures 1 day ago'] = shift_closures(closures,1)\n",
    "    closures['Closures 2 days ago'] = shift_closures(closures,2)\n",
    "    closures['Closures 3 days ago'] = shift_closures(closures,3)\n",
    "    closures['Closures 4 days ago'] = shift_closures(closures,4)\n",
    "    closures['Closures 5 days ago'] = shift_closures(closures,5)\n",
    "    closures['Closures 6 days ago'] = shift_closures(closures,6)\n",
    "    closures['Closures 7 days ago'] = shift_closures(closures,7)\n",
    "    closures['Closures 14 days ago'] = shift_closures(closures,14)\n",
    "    closures['Closures 30 days ago'] = shift_closures(closures,30)\n",
    "    closures['Closures 365 days ago'] = shift_closures(closures,365)\n",
    "    closures['Last 7 days closures'] = (closures['Closures 1 day ago']\n",
    "                                        + closures['Closures 2 days ago']\n",
    "                                        + closures['Closures 3 days ago']\n",
    "                                        + closures['Closures 4 days ago']\n",
    "                                        + closures['Closures 5 days ago']\n",
    "                                        + closures['Closures 6 days ago']\n",
    "                                        + closures['Closures 7 days ago'])\n",
    "    closures['Last 14 days closures'] = (closures['Last 7 days closures']\n",
    "                                         + get_last_14_days_closures(closures))\n",
    "    closures['Last 28 days closures'] = (closures['Last 14 days closures']\n",
    "                                         + get_last_28_days_closures(closures))\n",
    "    closures = closures.dropna()\n",
    "    closures = closures[closures['Location End Date'] >= business_start_date]\n",
    "    closures = closures[closures['Location End Date'] <= business_end_date]\n",
    "    return closures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1929,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openings_per_day_per_neighborhood(openings):\n",
    "    openings['Openings'] = 1\n",
    "    openings['Location Start Date'] = pd.to_datetime(openings['Location Start Date'])\n",
    "    openings = openings[openings['Location Start Date'].dt.year >= start_year-1]\n",
    "    openings = openings.groupby(['Location Start Date','Neighborhood']).count()\n",
    "    openings = openings.drop(columns=[ 'DBA Name','Location End Date'])\n",
    "    openings = openings.reset_index()\n",
    "    return openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1930,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zero_opening_neighborhoods(openings, neighborhoods):\n",
    "    new_rows = pd.DataFrame()\n",
    "    num_records = len(openings.index)\n",
    "    current_date = openings.iloc[0,0]\n",
    "    zero_opening_neighborhoods = copy.deepcopy(neighborhoods)\n",
    "    for record in range(0,num_records):\n",
    "        while openings.iloc[record,0] != current_date:\n",
    "            for neighborhood in zero_opening_neighborhoods:\n",
    "                new_row = {'Location Start Date' : current_date,\n",
    "                                   'Neighborhood' : neighborhood,\n",
    "                                   'Openings' : 0}\n",
    "                new_rows = new_rows.append(new_row,ignore_index=True)\n",
    "            current_date = current_date + timedelta(days=1)\n",
    "        if openings.iloc[record,0] == current_date:\n",
    "            zero_opening_neighborhoods.remove(openings.iloc[record,1])\n",
    "            if record != num_records-1:\n",
    "                if openings.iloc[record+1,0] != current_date:\n",
    "                    for neighborhood in zero_opening_neighborhoods:\n",
    "                        new_row = {'Location Start Date' : current_date,\n",
    "                                   'Neighborhood' : neighborhood,\n",
    "                                   'Openings' : 0}\n",
    "                        new_rows = new_rows.append(new_row,ignore_index=True)\n",
    "                    zero_opening_neighborhoods = copy.deepcopy(neighborhoods)\n",
    "                    current_date = current_date + timedelta(days=1)\n",
    "        if current_date == date_after_end_date:\n",
    "            break\n",
    "    for neighborhood in zero_opening_neighborhoods:\n",
    "        new_row = {'Location Start Date' : current_date,\n",
    "                    'Neighborhood' : neighborhood,\n",
    "                    'Openings' : 0}\n",
    "        new_rows = new_rows.append(new_row,ignore_index=True)\n",
    "    frames = [openings,new_rows]\n",
    "    new_record = pd.concat(frames)\n",
    "    new_record = new_record.sort_values(['Location Start Date','Neighborhood'])\n",
    "    return new_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1931,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_openings(openings,num_days):\n",
    "    transitional_data = openings.shift(periods=(num_neighbourhoods*num_days))\n",
    "    transitional_data = transitional_data['Openings']\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1932,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_14_days_openings(openings):\n",
    "    transitional_data = openings.shift(periods=(num_neighbourhoods*7))\n",
    "    transitional_data = transitional_data['Last 7 days openings']\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1933,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_28_days_openings(openings):\n",
    "    transitional_data = openings.shift(periods=(num_neighbourhoods*14))\n",
    "    transitional_data = transitional_data['Last 14 days openings']\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1934,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_opening_date_data(openings):\n",
    "    openings['Openings 1 day ago'] = shift_openings(openings,1)\n",
    "    openings['Openings 2 days ago'] = shift_openings(openings,2)\n",
    "    openings['Openings 3 days ago'] = shift_openings(openings,3)\n",
    "    openings['Openings 4 days ago'] = shift_openings(openings,4)\n",
    "    openings['Openings 5 days ago'] = shift_openings(openings,5)\n",
    "    openings['Openings 6 days ago'] = shift_openings(openings,6)\n",
    "    openings['Openings 7 days ago'] = shift_openings(openings,7)\n",
    "    openings['Openings 14 days ago'] = shift_openings(openings,14)\n",
    "    openings['Openings 30 days ago'] = shift_openings(openings,30)\n",
    "    openings['Openings 365 days ago'] = shift_openings(openings,365)\n",
    "    openings['Last 7 days openings'] = (openings['Openings 1 day ago']\n",
    "                                        + openings['Openings 2 days ago']\n",
    "                                        + openings['Openings 3 days ago']\n",
    "                                        + openings['Openings 4 days ago']\n",
    "                                        + openings['Openings 5 days ago']\n",
    "                                        + openings['Openings 6 days ago']\n",
    "                                        + openings['Openings 7 days ago'])\n",
    "    openings['Last 14 days openings'] = (openings['Last 7 days openings']\n",
    "                                         + get_last_14_days_openings(openings))\n",
    "    openings['Last 28 days openings'] = (openings['Last 14 days openings']\n",
    "                                         + get_last_28_days_openings(openings))\n",
    "    openings = openings.dropna()\n",
    "    openings = openings[openings['Location Start Date'] >= business_start_date]\n",
    "    openings = openings[openings['Location Start Date'] <= business_end_date]\n",
    "    return openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1935,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dates_for_each_business(df):\n",
    "    df['Date'] = np.nan\n",
    "    df['Date']= pd.to_datetime(df['Date'])\n",
    "    df['Location Start Date']= pd.to_datetime(df['Location Start Date'])\n",
    "    df['Location End Date']= pd.to_datetime(df['Location End Date'])\n",
    "    new_df = pd.DataFrame()\n",
    "    final_df = pd.DataFrame()\n",
    "    num_records = len(df.index)\n",
    "    current_date = one_year_before_start_date #one year prior to beginning of SFPD data\n",
    "    #end_date = end_date #final date of SFPD data\n",
    "    delta = timedelta(days = 1)\n",
    "    while current_date <= end_date:\n",
    "        #print (current_date.strftime(\"%Y-%m-%d\"))\n",
    "        num_records = len(df.index)\n",
    "        \n",
    "        #new_df = (df.loc[(df['Location Start Date'] <= current_date) & (current_date < df['Location End Date'])])\n",
    "        \n",
    "        new_df = (df.loc[(pd.to_datetime(df['Location Start Date']).dt.date <= current_date) \n",
    "                         & (current_date < pd.to_datetime(df['Location End Date']).dt.date)])\n",
    "        \n",
    "        \n",
    "        \n",
    "        new_df['Date'] = current_date\n",
    "        final_df = pd.concat((new_df,final_df))\n",
    "        current_date += delta\n",
    "    final_df['Number of businesses'] = 1\n",
    "    final_df = final_df.groupby(['Date','Neighborhood']).count()\n",
    "    final_df = final_df.drop(columns=[ 'DBA Name','Location Start Date',\n",
    "                           'Location End Date'])\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1936,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_days(df,num_days):\n",
    "    transitional_data = df.shift(periods=(num_neighbourhoods*num_days))\n",
    "    transitional_data = transitional_data['Number of businesses']\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1937,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_14_days(df):\n",
    "    transitional_data = df.shift(periods=(num_neighbourhoods*7))\n",
    "    transitional_data = transitional_data['Last 7 days']\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1938,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_28_days(df):\n",
    "    transitional_data = df.shift(periods=(num_neighbourhoods*14))\n",
    "    transitional_data = transitional_data['Last 14 days']\n",
    "    return transitional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1939,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_date_data(df):\n",
    "    df['Businesses 1 day ago'] = shift_days(df,1)\n",
    "    df['Businesses 2 days ago'] = shift_days(df,2)\n",
    "    df['Businesses 3 days ago'] = shift_days(df,3)\n",
    "    df['Businesses 4 days ago'] = shift_days(df,4)\n",
    "    df['Businesses 5 days ago'] = shift_days(df,5)\n",
    "    df['Businesses 6 days ago'] = shift_days(df,6)\n",
    "    df['Businesses 7 days ago'] = shift_days(df,7)\n",
    "    df['Businesses 14 days ago'] = shift_days(df,14)\n",
    "    df['Businesses 30 days ago'] = shift_days(df,30)\n",
    "    df['Businesses 365 days ago'] = shift_days(df,365)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3338: DtypeWarning: Columns (12,13,14,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "business_df = open_businesses()\n",
    "business_df = drop_unnecessary_columns(business_df)\n",
    "business_df.to_csv(\"bus_progress1.csv\", index = False)\n",
    "business_df = drop_end_dates_before_uber_legislation_change(business_df)\n",
    "business_df.to_csv(\"bus_progress2.csv\", index = False)\n",
    "business_df = determine_neighborhood_by_geolocation(business_df, neighborhood_polygons,neighborhoods)\n",
    "business_df.to_csv(\"bus_progress3.csv\", index = False)\n",
    "business_df = cleanup_columns(business_df)\n",
    "business_df.to_csv(\"bus_progress4.csv\", index = False)\n",
    "closures = business_df.copy(deep=True)\n",
    "closures.to_csv(\"clo_progress1.csv\", index = False)\n",
    "closures = get_closures_per_day_per_neighborhood(closures)\n",
    "closures.to_csv(\"clo_progress2.csv\", index = False)\n",
    "closures = add_zero_closure_neighborhoods(closures,neighborhoods)\n",
    "closures.to_csv(\"clo_progress3.csv\", index = False)\n",
    "closures = generate_new_closure_date_data(closures)\n",
    "closures.to_csv(\"clo_progress4.csv\", index = False)\n",
    "openings = business_df.copy(deep=True)\n",
    "openings.to_csv(\"ope_progress1.csv\", index = False)\n",
    "openings = get_openings_per_day_per_neighborhood(openings)\n",
    "openings.to_csv(\"ope_progress2.csv\", index = False)\n",
    "openings = add_zero_opening_neighborhoods(openings,neighborhoods)\n",
    "openings.to_csv(\"ope_progress3.csv\", index = False)\n",
    "openings = generate_new_opening_date_data(openings)\n",
    "openings.to_csv(\"ope_progress4.csv\", index = False)\n",
    "business_df = generate_dates_for_each_business(business_df)\n",
    "business_df.to_csv(\"bus_progress5.csv\", index = False)\n",
    "business_df = generate_new_date_data(business_df)\n",
    "business_df.to_csv(\"bus_progress6.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Merge dataframes<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalise_data(sfpd_data,businesses,openings,closures):\n",
    "    sfpd_data.rename(columns={\"1 day ago\": \"Crime 1 day ago\",\n",
    "                              \"2 days ago\": \"Crime 2 days ago\",\n",
    "                              \"3 days ago\": \"Crime 3 days ago\",\n",
    "                              \"4 days ago\": \"Crime 4 days ago\",\n",
    "                              \"5 days ago\": \"Crime 5 days ago\",\n",
    "                              \"6 days ago\": \"Crime 6 days ago\",\n",
    "                              \"7 days ago\": \"Crime 7 days ago\",\n",
    "                              \"14 days ago\": \"Crime 14 days ago\",\n",
    "                              \"30 days ago\": \"Crime 30 days ago\",\n",
    "                              \"365 days ago\": \"Crime 365 days ago\",\n",
    "                              \"Last 7 days\": \"Last 7 days crime\",\n",
    "                              \"Last 14 days\": \"Last 14 days crime\",\n",
    "                              \"Last 28 days\": \"Last 28 days crime\"})\n",
    "    sfpd_data['Number of businesses'] = businesses['Number of businesses']\n",
    "    sfpd_data['Businesses 1 day ago'] = businesses['Businesses 1 day ago']\n",
    "    sfpd_data['Businesses 2 days ago'] = businesses['Businesses 2 days ago']\n",
    "    sfpd_data['Businesses 3 days ago'] = businesses['Businesses 3 days ago']\n",
    "    sfpd_data['Businesses 4 days ago'] = businesses['Businesses 4 days ago']\n",
    "    sfpd_data['Businesses 5 days ago'] = businesses['Businesses 5 days ago']\n",
    "    sfpd_data['Businesses 6 days ago'] = businesses['Businesses 6 days ago']\n",
    "    sfpd_data['Businesses 7 days ago'] = businesses['Businesses 7 days ago']\n",
    "    sfpd_data['Businesses 14 days ago'] = businesses['Businesses 14 days ago']\n",
    "    sfpd_data['Businesses 30 days ago'] = businesses['Businesses 30 days ago']\n",
    "    sfpd_data['Businesses 365 days ago'] = businesses['Businesses 365 days ago']\n",
    "    sfpd_data['Number of closures'] = closures['Closures']\n",
    "    sfpd_data['Closures 1 day ago'] = closures['Closures 1 day ago']\n",
    "    sfpd_data['Closures 2 days ago'] = closures['Closures 2 days ago']\n",
    "    sfpd_data['Closures 3 days ago'] = closures['Closures 3 days ago']\n",
    "    sfpd_data['Closures 4 days ago'] = closures['Closures 4 days ago']\n",
    "    sfpd_data['Closures 5 days ago'] = closures['Closures 5 days ago']\n",
    "    sfpd_data['Closures 6 days ago'] = closures['Closures 6 days ago']\n",
    "    sfpd_data['Closures 7 days ago'] = closures['Closures 7 days ago']\n",
    "    sfpd_data['Closures 14 days ago'] = closures['Closures 14 days ago']\n",
    "    sfpd_data['Closures 30 days ago'] = closures['Closures 30 days ago']\n",
    "    sfpd_data['Closures 365 days ago'] = closures['Closures 365 days ago']\n",
    "    sfpd_data['Last 7 days closures'] = closures['Last 7 days closures']\n",
    "    sfpd_data['Last 14 days closures'] = closures['Last 14 days closures']\n",
    "    sfpd_data['Last 28 days closures'] = closures['Last 28 days closures']\n",
    "    sfpd_data['Number of openings'] = openings['Openings']\n",
    "    sfpd_data['Openings 1 day ago'] = openings['Openings 1 day ago']\n",
    "    sfpd_data['Openings 2 days ago'] = openings['Openings 2 days ago']\n",
    "    sfpd_data['Openings 3 days ago'] = openings['Openings 3 days ago']\n",
    "    sfpd_data['Openings 4 days ago'] = openings['Openings 4 days ago']\n",
    "    sfpd_data['Openings 5 days ago'] = openings['Openings 5 days ago']\n",
    "    sfpd_data['Openings 6 days ago'] = openings['Openings 6 days ago']\n",
    "    sfpd_data['Openings 7 days ago'] = openings['Openings 7 days ago']\n",
    "    sfpd_data['Openings 14 days ago'] = openings['Openings 14 days ago']\n",
    "    sfpd_data['Openings 30 days ago'] = openings['Openings 30 days ago']\n",
    "    sfpd_data['Openings 365 days ago'] = openings['Openings 365 days ago']\n",
    "    sfpd_data['Last 7 days openings'] = openings['Last 7 days openings']\n",
    "    sfpd_data['Last 14 days openings'] = openings['Last 14 days openings']\n",
    "    sfpd_data['Last 28 days openings'] = openings['Last 28 days openings']\n",
    "    sfpd_data = sfpd_data.drop(columns=['Incident Date','Incident Year'])\n",
    "    return sfpd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_day_of_week(df):\n",
    "    dummies = pd.get_dummies(df['Incident Day of Week'])\n",
    "    merged = pd.concat([df,dummies],axis='columns')\n",
    "    final = merged.drop(['Incident Day of Week','Monday'],axis='columns')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_neighborhood(df):\n",
    "    dummies = pd.get_dummies(df['Neighborhood'])\n",
    "    merged = pd.concat([df,dummies],axis='columns')\n",
    "    final = merged.drop(['Neighborhood','Ashbury Heights'],axis='columns')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(df):\n",
    "    y_data = df[['Todays Reports']]\n",
    "    x_data = df.drop(columns=['Todays Reports'])\n",
    "    x_data = x_data.apply(lambda x: (x - x.min(axis = 0)) / (x.max(axis = 0) - x.min(axis = 0)))\n",
    "    x_data['Todays Reports'] = y_data['Todays Reports']\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Incidents to merge\")\n",
    "print(sfpd_df)\n",
    "print(\"Business to merge\")\n",
    "print(business_df)\n",
    "print(\"Openings to merge\")\n",
    "print(openings)\n",
    "print(\"Closures to merge\")\n",
    "print(closures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfpd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = finalise_data(sfpd_df,business_df,openings,closures)\n",
    "final_data = convert_neighborhood(final_data)\n",
    "final_data = convert_day_of_week(final_data)\n",
    "final_data = normalise_data(final_data)\n",
    "final_data\n",
    "final_data.to_csv(final_data_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1914,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfpd_df.to_csv(final_data_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
